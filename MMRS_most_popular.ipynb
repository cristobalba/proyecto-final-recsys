{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "\n",
    "import pyreclab\n",
    "\n",
    "from surprise import AlgoBase\n",
    "from surprise import NormalPredictor\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNBaseline\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import NMF\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializar originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants and initialization\n",
    "dataset = 'ml'  #options:'lfm', anime', 'book', 'ml'\n",
    "folds = 5\n",
    "my_seed = 0\n",
    "rd.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "top_fraction = 0.2\n",
    "user_events_file = dataset + '/user_events.txt'\n",
    "low_user_file = dataset + '/low_main_users.txt'\n",
    "medium_user_file = dataset + '/medium_main_users.txt'\n",
    "high_user_file = dataset + '/high_main_users.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read user events and users\n",
    "# cols = ['user', 'item', 'preference']\n",
    "# df_events = pd.read_csv(user_events_file, sep=',', names=cols, skiprows=1)\n",
    "# print('No. of user events: ' + str(len(df_events)))\n",
    "# # read users\n",
    "# low_users = pd.read_csv(low_user_file, sep=',').set_index('user')\n",
    "# medium_users = pd.read_csv(medium_user_file, sep=',').set_index('user')\n",
    "# high_users = pd.read_csv(high_user_file, sep=',').set_index('user')\n",
    "# no_users = len(low_users) + len(medium_users) + len(high_users)\n",
    "# print('No. of users: ' + str(no_users))\n",
    "# print('No. of events per user: ' + str(len(df_events) / no_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializar new anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read user events and users\n",
    "# cols = ['user', 'item', 'preference']\n",
    "# df_events = pd.read_csv('./myanime_600K.csv', sep=',', names=cols)\n",
    "# df_events = df_events.rename(columns={'user_id': 'user', 'anime_id': 'item', 'rating': 'preference'})\n",
    "# print('No. of user events: ' + str(len(df_events)))\n",
    "# # read users\n",
    "# low_users = pd.read_csv('./myanime/bot.csv', sep=',').set_index('user')\n",
    "# medium_users = pd.read_csv('./myanime/mid.csv', sep=',').set_index('user')\n",
    "# high_users = pd.read_csv('./myanime/top.csv', sep=',').set_index('user')\n",
    "# no_users = len(low_users) + len(medium_users) + len(high_users)\n",
    "# print('No. of users: ' + str(no_users))\n",
    "# print('No. of events per user: ' + str(len(df_events) / no_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializar netflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of user events: 459514\n",
      "No. of users: 3000\n",
      "No. of events per user: 153.17133333333334\n"
     ]
    }
   ],
   "source": [
    "# read user events and users\n",
    "cols = ['user', 'item', 'preference']\n",
    "df_events = pd.read_csv('./netflix/netflix.csv', sep=',')\n",
    "df_events = df_events.rename(columns={'user_id': 'user', 'item_id': 'item', 'rating': 'preference'})\n",
    "print('No. of user events: ' + str(len(df_events)))\n",
    "# read users\n",
    "low_users = pd.read_csv('./netflix/bot.csv', sep=',').set_index('user_id')\n",
    "medium_users = pd.read_csv('./netflix/mid.csv', sep=',').set_index('user_id')\n",
    "high_users = pd.read_csv('./netflix/top.csv', sep=',').set_index('user_id')\n",
    "no_users = len(low_users) + len(medium_users) + len(high_users)\n",
    "print('No. of users: ' + str(no_users))\n",
    "print('No. of events per user: ' + str(len(df_events) / no_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(model, test_df, topN):\n",
    "    low_prec = []\n",
    "    medium_prec = []\n",
    "    high_prec = []\n",
    "    for user_id in test_df['user'].unique():\n",
    "        precision = model.precision( f'{user_id}', \n",
    "                                topn = topN,\n",
    "                                relevance_threshold = 0,\n",
    "                                include_rated = False )\n",
    "        if user_id in low_users.index:\n",
    "            low_prec.append(precision)\n",
    "        elif user_id in medium_users.index:\n",
    "            medium_prec.append(precision)\n",
    "        else:\n",
    "            high_prec.append(precision)\n",
    "    return np.mean(low_prec), np.mean(medium_prec), np.mean(high_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(model, test_df, topN):\n",
    "    low_recall = []\n",
    "    medium_recall = []\n",
    "    high_recall = []\n",
    "    for user_id in test_df['user'].unique():\n",
    "        recall = model.recall( str(user_id),\n",
    "                                topn = topN,\n",
    "                                relevance_threshold = 0,\n",
    "                                include_rated = False )\n",
    "        if user_id in low_users.index:\n",
    "            low_recall.append(recall)\n",
    "        elif user_id in medium_users.index:\n",
    "            medium_recall.append(recall)\n",
    "        else:\n",
    "            high_recall.append(recall)\n",
    "    return np.mean(low_recall), np.mean(medium_recall), np.mean(high_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Precision:  0.0580030354074601\n",
      "Medium Precision:  0.09284732714508113\n",
      "High Precision:  0.07965375621723551\n",
      "All Precision:  0.07683470625659224\n",
      "\n",
      "\n",
      "Low Recall:  0.024346900975211902\n",
      "Medium Recall:  0.04391453008944767\n",
      "High Recall:  0.07611538560635847\n",
      "All Recall:  0.04812560555700602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state = my_seed)\n",
    "kfold_data = kf.split(df_events)\n",
    "kfold = 1\n",
    "topN = 10\n",
    "low_precisions = []\n",
    "mid_precisions = []\n",
    "high_precisions = []\n",
    "low_recalls = []\n",
    "mid_recalls = []\n",
    "high_recalls = []\n",
    "count = 1\n",
    "\n",
    "for trainset, testset in kfold_data:\n",
    "    train_df = df_events.iloc[trainset]\n",
    "    test_df = df_events.iloc[testset]\n",
    "    train_df.to_csv(f'./most pop data/train{count}.csv', index=False)\n",
    "    test_df.to_csv(f'./most pop data/test{count}.csv', index=False)\n",
    "\n",
    "    # Convertir el DataFrame a la estructura esperada por pyreclab\n",
    "    train_ratings = train_df[['user', 'item', 'preference']].values.tolist()\n",
    "\n",
    "    # Inicializar y entrenar el modelo\n",
    "    model = pyreclab.MostPopular( dataset = './most pop data/train' + str(count) + '.csv',\n",
    "                                dlmchar=b',',\n",
    "                                header = True,\n",
    "                                usercol = 0,\n",
    "                                itemcol = 1,\n",
    "                                ratingcol = 2 )\n",
    "    model.train()\n",
    "\n",
    "    recommendList, maprec, ndcg = model.testrec(input_file='./most pop data/test' + str(count) + '.csv',\n",
    "                                          dlmchar=b',',\n",
    "                                          header=False,\n",
    "                                          usercol=0,\n",
    "                                          itemcol=1,\n",
    "                                          ratingcol=2,\n",
    "                                          topn=topN,\n",
    "                                          relevance_threshold=0,\n",
    "                                          includeRated=False)\n",
    "\n",
    "    # Calcular las precisions\n",
    "    low_precision, mid_precision, high_precision = calculate_precision(model, test_df, topN)\n",
    "    low_precisions.append(low_precision)\n",
    "    mid_precisions.append(mid_precision)\n",
    "    high_precisions.append(high_precision)\n",
    "    \n",
    "    # Calcular las recalls\n",
    "    low_recall, mid_recall, high_recall = calculate_recall(model, test_df, topN)\n",
    "    low_recalls.append(low_recall)\n",
    "    mid_recalls.append(mid_recall)\n",
    "    high_recalls.append(high_recall)\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "all_precision = np.mean([low_precisions, mid_precisions, high_precisions])\n",
    "all_recall = np.mean([low_recalls, mid_recalls, high_recalls])\n",
    "\n",
    "print('Low Precision: ', np.mean(low_precisions))\n",
    "print('Medium Precision: ', np.mean(mid_precisions))\n",
    "print('High Precision: ', np.mean(high_precisions))\n",
    "print('All Precision: ', all_precision)\n",
    "print('\\n')\n",
    "print('Low Recall: ', np.mean(low_recalls))\n",
    "print('Medium Recall: ', np.mean(mid_recalls))\n",
    "print('High Recall: ', np.mean(high_recalls))\n",
    "print('All Recall: ', all_recall)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall y Precision con MOST POPULAR\n",
    "ANIME:\n",
    "* Low Precision:  0.07180000134408475\n",
    "* Medium Precision:  0.10962000215649606\n",
    "* High Precision:  0.11118000219613314\n",
    "* All Precision:  0.09753333523223798\n",
    "\n",
    "* Low Recall:  0.012959075435390696\n",
    "* Medium Recall:  0.03867494782991707\n",
    "* High Recall:  0.06998966443855316\n",
    "* All Recall:  0.04054122923462031\n",
    "\n",
    "BOOKS:\n",
    "* Low Precision:  0.011920000185072421\n",
    "* Medium Precision:  0.02654000042229891\n",
    "* High Precision:  0.030840000510215758\n",
    "* All Precision:  0.02310000037252903\n",
    "\n",
    "* Low Recall:  0.00416008519846946\n",
    "* Medium Recall:  0.0074944833249785\n",
    "* High Recall:  0.01176950469762087\n",
    "* All Recall:  0.007808024407022943\n",
    "\n",
    "MOVIELENS:\n",
    "* Low Precision:  0.10162000198364259\n",
    "* Medium Precision:  0.11240000228583813\n",
    "* High Precision:  0.1223000024497509\n",
    "* All Precision:  0.11210666890641052\n",
    "\n",
    "* Low Recall:  0.0165079234149307\n",
    "* Medium Recall:  0.033235900679510086\n",
    "* High Recall:  0.061033416801132265\n",
    "* All Recall:  0.03692574696519102\n",
    "\n",
    "LASTFM:\n",
    "* Low Precision:  0.059540001083910464\n",
    "* Medium Precision:  0.09260000180304051\n",
    "* High Precision:  0.09624000196456908\n",
    "* All Precision:  0.0827933349505067\n",
    "\n",
    "* Low Recall:  0.009334813251486048\n",
    "* Medium Recall:  0.009003960465663114\n",
    "* High Recall:  0.012973698530229737\n",
    "* All Recall:  0.0104374907491263\n",
    "\n",
    "NEW ANIME\n",
    "* Low Precision:  0.09143458506065552\n",
    "* Medium Precision:  0.10682347217294035\n",
    "* High Precision:  0.09647292604811222\n",
    "* All Precision:  0.09824366109390271\n",
    "\n",
    "* Low Recall:  0.025005798261108585\n",
    "* Medium Recall:  0.04312398380231956\n",
    "* High Recall:  0.060711176127519216\n",
    "* All Recall:  0.04294698606364911\n",
    "\n",
    "Netflix\n",
    "* Low Precision:  0.0580030354074601\n",
    "* Medium Precision:  0.09284732714508113\n",
    "* High Precision:  0.07965375621723551\n",
    "* All Precision:  0.07683470625659224\n",
    "\n",
    "* Low Recall:  0.024346900975211902\n",
    "* Medium Recall:  0.04391453008944767\n",
    "* High Recall:  0.07611538560635847\n",
    "* All Recall:  0.04812560555700602"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
