{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "\n",
    "from surprise import AlgoBase\n",
    "from surprise import NormalPredictor\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNBaseline\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import NMF\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants and initialization\n",
    "dataset = 'lfm'  #options:'lfm', anime', 'book', 'ml'\n",
    "folds = 5\n",
    "my_seed = 0\n",
    "rd.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "top_fraction = 0.2\n",
    "user_events_file = dataset + '/user_events.txt'\n",
    "low_user_file = dataset + '/low_main_users.txt'\n",
    "medium_user_file = dataset + '/medium_main_users.txt'\n",
    "high_user_file = dataset + '/high_main_users.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of user events: 1755361\n",
      "No. of users: 3000\n",
      "No. of events per user: 585.1203333333333\n"
     ]
    }
   ],
   "source": [
    "# read user events and users\n",
    "cols = ['user', 'item', 'preference']\n",
    "df_events = pd.read_csv(user_events_file, sep=',', names=cols, skiprows=1)\n",
    "print('No. of user events: ' + str(len(df_events)))\n",
    "# read users\n",
    "low_users = pd.read_csv(low_user_file, sep=',').set_index('user')\n",
    "medium_users = pd.read_csv(medium_user_file, sep=',').set_index('user')\n",
    "high_users = pd.read_csv(high_user_file, sep=',').set_index('user')\n",
    "no_users = len(low_users) + len(medium_users) + len(high_users)\n",
    "print('No. of users: ' + str(no_users))\n",
    "print('No. of events per user: ' + str(len(df_events) / no_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. items: 352805\n",
      "No. of events per item: 4.9754425249075265\n"
     ]
    }
   ],
   "source": [
    "# get item distribution\n",
    "item_dist = df_events['item'].value_counts()\n",
    "num_items = len(item_dist)\n",
    "print('No. items: ' + str(num_items))\n",
    "# create item dataframe with normalized item counts\n",
    "df_item_dist = pd.DataFrame(item_dist)\n",
    "df_item_dist.columns = ['count']\n",
    "df_item_dist['count'] /= no_users\n",
    "print('No. of events per item: ' + str(len(df_events) / num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983415191583641"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sparsity\n",
    "1 - len(df_events) / (no_users * num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min rating: 1.0\n",
      "Max rating: 1000.0\n"
     ]
    }
   ],
   "source": [
    "# rating range\n",
    "print('Min rating: ' + str(df_events['preference'].min()))\n",
    "print('Max rating: ' + str(df_events['preference'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get fractions\n",
    "# user_hist = [] # user history sizes\n",
    "# pop_item_fraq = [] # average popularity of items in user profiles\n",
    "# for u, df in df_events.groupby('user'):\n",
    "#     no_user_items = len(set(df['item'])) # profile size\n",
    "#     user_hist.append(no_user_items)\n",
    "#     # get popularity (= fraction of users interacted with item) of user items and calculate average of it\n",
    "#     user_pop_item_fraq = sum(item_dist[df['item']] / no_users) / no_user_items\n",
    "#     pop_item_fraq.append(user_pop_item_fraq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# slope, intercept, r_value, p_value, std_err = stats.linregress(user_hist, pop_item_fraq)\n",
    "# print('R-value: ' + str(r_value))\n",
    "# print('R2-value: ' + str(r_value**2))\n",
    "# print('P-value: ' + str(p_value))\n",
    "# print('Slope: ' + str(slope))\n",
    "# print('Intercept: ' + str(intercept))\n",
    "# print(stats.spearmanr(user_hist, pop_item_fraq))\n",
    "\n",
    "# line = slope * np.array(user_hist) + intercept\n",
    "# plt.plot(user_hist, pop_item_fraq, 'o', user_hist, line)\n",
    "# plt.xlabel('User profile size', fontsize='15')\n",
    "# plt.ylabel('Average popularity of items', fontsize='15')\n",
    "# plt.xticks(fontsize='13')\n",
    "# plt.yticks(fontsize='13')\n",
    "# #plt.savefig('data/' + dataset + '/plots/corr_user_avg.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(df_events['preference'].min(), df_events['preference'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<surprise.dataset.DatasetAutoFolds object at 0x7f980d4cefb0>\n"
     ]
    }
   ],
   "source": [
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df_events, reader)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae_of_groups(predictions):\n",
    "    #print('All: ')\n",
    "    #all_mae = accuracy.mae(predictions)\n",
    "    all_predictions = []\n",
    "    low_predictions = []\n",
    "    med_predictions = []\n",
    "    high_predictions = []\n",
    "    for uid, iid, true_r, est, details in predictions:\n",
    "        prediction = [(uid, iid, true_r, est, details)]\n",
    "        if uid in low_users.index:\n",
    "            low_predictions.append(accuracy.mae(prediction, verbose=False))\n",
    "        elif uid in medium_users.index:\n",
    "            med_predictions.append(accuracy.mae(prediction, verbose=False))\n",
    "        else:\n",
    "            high_predictions.append(accuracy.mae(prediction, verbose=False))          \n",
    "    low_mae = np.mean(low_predictions)\n",
    "    #print('LowMS: ' + str(low_mae))\n",
    "    med_mae = np.mean(med_predictions)\n",
    "    #print('MedMS: ' + str(med_mae))\n",
    "    high_mae = np.mean(high_predictions)\n",
    "    #print('HighMS: ' + str(high_mae))\n",
    "    all_mae = np.mean([low_mae, med_mae, high_mae])\n",
    "    #print('All: ' + str(all_mae))\n",
    "    print('Low vs. med: ' + str(stats.ttest_ind(low_predictions, med_predictions)))\n",
    "    print('Low vs. high: ' + str(stats.ttest_ind(low_predictions, high_predictions)))\n",
    "    \n",
    "    return low_mae, med_mae, high_mae, all_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "    low_precisions = []\n",
    "    med_precisions = []\n",
    "    high_precisions = []\n",
    "    low_recalls = []\n",
    "    med_recalls = []\n",
    "    high_recalls = []\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    for uid in precisions.keys():\n",
    "        if uid in low_users.index:\n",
    "            low_precisions.append(precisions[uid])\n",
    "            low_recalls.append(recalls[uid])\n",
    "        elif uid in medium_users.index:\n",
    "            med_precisions.append(precisions[uid])\n",
    "            med_recalls.append(recalls[uid])\n",
    "        else:\n",
    "            high_precisions.append(precisions[uid])\n",
    "            high_recalls.append(recalls[uid])\n",
    "    \n",
    "    return np.mean(low_precisions), np.mean(med_precisions), np.mean(high_precisions), np.mean(low_recalls), np.mean(med_recalls), np.mean(high_recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNNBasic\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Low Precision: 0.6717803968253968\n",
      "Med Precision: 0.6926784920634921\n",
      "High Precision: 0.7676726984126985\n",
      "All Precision: 0.7107105291005291\n",
      "\n",
      "\n",
      "Low Recall: 0.21364471295990822\n",
      "Med Recall: 0.15192751591900525\n",
      "High Recall: 0.23994027398395787\n",
      "All Recall: 0.2018375009542904\n",
      "KNNWithMeans\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Low Precision: 0.6731023809523811\n",
      "Med Precision: 0.6880788095238095\n",
      "High Precision: 0.7559572222222223\n",
      "All Precision: 0.7057128042328042\n",
      "\n",
      "\n",
      "Low Recall: 0.21294207683498362\n",
      "Med Recall: 0.14992896860078572\n",
      "High Recall: 0.23615352781749904\n",
      "All Recall: 0.19967485775108945\n",
      "NMF\n",
      "Low Precision: 0.6312755555555556\n",
      "Med Precision: 0.598235238095238\n",
      "High Precision: 0.6549547619047619\n",
      "All Precision: 0.6281551851851852\n",
      "\n",
      "\n",
      "Low Recall: 0.1965284343490094\n",
      "Med Recall: 0.1295440782539194\n",
      "High Recall: 0.20650777629230252\n",
      "All Recall: 0.1775267629650771\n",
      "CoClustering\n",
      "Low Precision: 0.672306507936508\n",
      "Med Precision: 0.6898487301587302\n",
      "High Precision: 0.7660446031746032\n",
      "All Precision: 0.709399947089947\n",
      "\n",
      "\n",
      "Low Recall: 0.21368047819309094\n",
      "Med Recall: 0.15228889489132955\n",
      "High Recall: 0.2421086986639204\n",
      "All Recall: 0.20269269058278033\n"
     ]
    }
   ],
   "source": [
    "sim_users = {'name': 'cosine', 'user_based': True}  # compute cosine similarities between users\n",
    "algos = []\n",
    "\n",
    "algos.append(KNNBasic(sim_options = sim_users, k=40)) \n",
    "algos.append(KNNWithMeans(sim_options = sim_users, k=40))\n",
    "algos.append(NMF(n_factors = 30, random_state=my_seed))\n",
    "algos.append(CoClustering(n_cltr_u=3, n_cltr_i=3, random_state=my_seed))\n",
    "algo_names = ['KNNBasic',\n",
    "              'KNNWithMeans',\n",
    "              'NMF',\n",
    "              'CoClustering']\n",
    "\n",
    "kf = KFold(n_splits=folds, random_state = my_seed)\n",
    "for i in range(0, len(algo_names)):\n",
    "    df_item_dist[algo_names[i]] = 0\n",
    "    # low_maes = []\n",
    "    # med_maes = []\n",
    "    # high_maes = []\n",
    "    # all_maes = []\n",
    "    low_precisions = []\n",
    "    med_precisions = []\n",
    "    high_precisions = []\n",
    "    all_precisions = []\n",
    "    low_recalls = []\n",
    "    med_recalls = []\n",
    "    high_recalls = []\n",
    "    all_recalls = []\n",
    "\n",
    "    print(algo_names[i])\n",
    "    fold_count = 0\n",
    "    for trainset, testset in kf.split(data):\n",
    "        # calculate and evaluate recommendations\n",
    "        algos[i].fit(trainset)\n",
    "        predictions = algos[i].test(testset)        \n",
    "        # low_mae, med_mae, high_mae, all_mae = get_mae_of_groups(predictions)\n",
    "        # low_maes.append(low_mae)\n",
    "        # med_maes.append(med_mae)\n",
    "        # high_maes.append(high_mae)\n",
    "        # all_maes.append(all_mae)\n",
    "\n",
    "        # calculate precision and recall\n",
    "        low_precision, mid_precision, high_precision, low_recall, mid_recall, high_recall = precision_recall_at_k(predictions, k=10, threshold=3.5)\n",
    "        low_precisions.append(low_precision)\n",
    "        med_precisions.append(mid_precision)\n",
    "        high_precisions.append(high_precision)\n",
    "        all_precisions.append(np.mean([low_precision, mid_precision, high_precision]))\n",
    "\n",
    "        low_recalls.append(low_recall)\n",
    "        med_recalls.append(mid_recall)\n",
    "        high_recalls.append(high_recall)\n",
    "        all_recalls.append(np.mean([low_recall, mid_recall, high_recall]))\n",
    "\n",
    "        # get top-n recommendation counts\n",
    "        # top_n = get_top_n(predictions, n=10)\n",
    "        # for uid, user_ratings in top_n.items():\n",
    "        #     for (iid, _) in user_ratings:\n",
    "        #         df_item_dist.loc[iid, algo_names[i]] += 1\n",
    "        \n",
    "    # print('LowMS: ' + str(np.mean(low_maes)))\n",
    "    # print('MedMS: ' + str(np.mean(med_maes)))\n",
    "    # print('HighMS: ' + str(np.mean(high_maes)))\n",
    "    # print('All: ' + str(np.mean(all_maes)))\n",
    "    print('Low Precision: ' + str(np.mean(low_precisions)))\n",
    "    print('Med Precision: ' + str(np.mean(med_precisions)))\n",
    "    print('High Precision: ' + str(np.mean(high_precisions)))\n",
    "    print('All Precision: ' + str(np.mean(all_precisions)))\n",
    "    print('\\n')\n",
    "    print('Low Recall: ' + str(np.mean(low_recalls)))\n",
    "    print('Med Recall: ' + str(np.mean(med_recalls)))\n",
    "    print('High Recall: ' + str(np.mean(high_recalls)))\n",
    "    print('All Recall: ' + str(np.mean(all_recalls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, len(algo_names)):\n",
    "#     plt.figure()\n",
    "#     x = df_item_dist['count']\n",
    "#     y = df_item_dist[algo_names[i]]\n",
    "#     #plt.gca().set_ylim(0, 300)\n",
    "#     slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "#     line = slope * np.array(x) + intercept\n",
    "#     print(algo_names[i])\n",
    "#     print(stats.spearmanr(x, y))\n",
    "#     plt.plot(x, y, 'o', x, line)\n",
    "#     plt.xlabel('Item popularity', fontsize='15')\n",
    "#     plt.ylabel('Recommendation frequency', fontsize='15')\n",
    "#     plt.xticks(fontsize='13')\n",
    "#     plt.yticks(fontsize='13')\n",
    "#     #plt.savefig('data/' + dataset + '/plots/rec_' + algo_names[i] + '.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNBasic\n",
    "\n",
    "* Low Precision: 0.7704684920634921\n",
    "* Med Precision: 0.798344126984127\n",
    "* High Precision: 0.7915609523809524\n",
    "* All Precision: 0.7867911904761905\n",
    "\n",
    "* Low Recall: 0.33841475348709904\n",
    "* Med Recall: 0.4577492550791713\n",
    "* High Recall: 0.6210483597199806\n",
    "* All Recall: 0.47240412276208354\n",
    "\n",
    "KNNWithMeans\n",
    "* Low Precision: 0.6965993650793652\n",
    "* Med Precision: 0.7756833333333335\n",
    "* High Precision: 0.786331507936508\n",
    "* All Precision: 0.7528714021164022\n",
    "\n",
    "* Low Recall: 0.2538119181328916\n",
    "* Med Recall: 0.3918997939115019\n",
    "* High Recall: 0.5819585612029813\n",
    "* All Recall: 0.4092234244157916\n",
    "\n",
    "NMF\n",
    "* Low Precision: 0.7527957936507936\n",
    "* Med Precision: 0.78965\n",
    "* High Precision: 0.7886530952380953\n",
    "* All Precision: 0.7770329629629631\n",
    "\n",
    "* Low Recall: 0.3281243813860379\n",
    "* Med Recall: 0.455435270841933\n",
    "* High Recall: 0.6178257154555379\n",
    "* All Recall: 0.4671284558945029\n",
    "\n",
    "CoClustering\n",
    "* Low Precision: 0.7465554761904762\n",
    "* Med Precision: 0.7995379365079366\n",
    "* High Precision: 0.7972762698412699\n",
    "* All Precision: 0.7811232275132276\n",
    "\n",
    "* Low Recall: 0.28726400365063925\n",
    "* Med Recall: 0.42888337935572823\n",
    "* High Recall: 0.6050122296094746\n",
    "* All Recall: 0.44038653753861406\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNBasic\n",
    "\n",
    "* Low Precision: 0.9945884126984128\n",
    "* Med Precision: 0.9972578571428571\n",
    "* High Precision: 0.9962325396825398\n",
    "* All Precision: 0.9960262698412699\n",
    "\n",
    "* Low Recall: 0.3010750950781106\n",
    "* Med Recall: 0.42410904956695106\n",
    "* High Recall: 0.6665163599731005\n",
    "* All Recall: 0.463900168206054\n",
    "\n",
    "KNNWithMeans\n",
    "* Low Precision: 0.9929084126984126\n",
    "* Med Precision: 0.9974978571428572\n",
    "* High Precision: 0.9965325396825397\n",
    "* All Precision: 0.9956462698412698\n",
    "\n",
    "* Low Recall: 0.3008656489549565\n",
    "* Med Recall: 0.4241893817579811\n",
    "* High Recall: 0.6666790484474276\n",
    "* All Recall: 0.46391135972012176\n",
    "\n",
    "NMF\n",
    "* Low Precision: 0.993325634920635\n",
    "* Med Precision: 0.9971578571428571\n",
    "* High Precision: 0.9962125396825396\n",
    "* All Precision: 0.9955653439153439\n",
    "\n",
    "* Low Recall: 0.3007827932626696\n",
    "* Med Recall: 0.42412373934078645\n",
    "* High Recall: 0.6665027390613784\n",
    "* All Recall: 0.46380309055494473\n",
    "\n",
    "CoClustering\n",
    "* Low Precision: 0.9930684126984127\n",
    "* Med Precision: 0.9970778571428571\n",
    "* High Precision: 0.9965725396825397\n",
    "* All Precision: 0.9955729365079365\n",
    "\n",
    "* Low Recall: 0.30067954029541677\n",
    "* Med Recall: 0.4240182979573649\n",
    "* High Recall: 0.6667154636596091\n",
    "* All Recall: 0.4638044339707969\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNBasic\n",
    "* Low Precision: 0.9909996031746031\n",
    "* Med Precision: 0.99301126984127\n",
    "* High Precision: 0.9934638095238094\n",
    "* All Precision: 0.9924915608465609\n",
    "\n",
    "* Low Recall: 0.5092605070850196\n",
    "* Med Recall: 0.4620812954025634\n",
    "* High Recall: 0.5173442636697978\n",
    "* All Recall: 0.49622868871912684\n",
    "\n",
    "KNNWithMeans\n",
    "* Low Precision: 0.9916887301587302\n",
    "* Med Precision: 0.9932912698412698\n",
    "* High Precision: 0.9936838095238094\n",
    "* All Precision: 0.9928879365079364\n",
    "\n",
    "* Low Recall: 0.5093677488973936\n",
    "* Med Recall: 0.4622402678622658\n",
    "* High Recall: 0.5174850764919627\n",
    "* All Recall: 0.4963643644172073\n",
    "\n",
    "NMF\n",
    "* Low Precision: 0.9917019047619048\n",
    "* Med Precision: 0.99313126984127\n",
    "* High Precision: 0.9937546031746031\n",
    "* All Precision: 0.9928625925925927\n",
    "\n",
    "* Low Recall: 0.5085475026055173\n",
    "* Med Recall: 0.46179779789501013\n",
    "* High Recall: 0.5172949705413175\n",
    "* All Recall: 0.49588009034728164\n",
    "\n",
    "CoClustering\n",
    "* Low Precision: 0.9915996031746033\n",
    "* Med Precision: 0.9929512698412697\n",
    "* High Precision: 0.993372380952381\n",
    "* All Precision: 0.9926410846560847\n",
    "\n",
    "* Low Recall: 0.5095295354945317\n",
    "* Med Recall: 0.46226876594519695\n",
    "* High Recall: 0.5173457822555484\n",
    "* All Recall: 0.496381361231759"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNBasic\n",
    "\n",
    "* Low Precision: 0.6717803968253968\n",
    "* Med Precision: 0.6926784920634921\n",
    "* High Precision: 0.7676726984126985\n",
    "* All Precision: 0.7107105291005291\n",
    "\n",
    "* Low Recall: 0.21364471295990822\n",
    "* Med Recall: 0.15192751591900525\n",
    "* High Recall: 0.23994027398395787\n",
    "* All Recall: 0.2018375009542904\n",
    "\n",
    "KNNWithMeans\n",
    "* Low Precision: 0.6731023809523811\n",
    "* Med Precision: 0.6880788095238095\n",
    "* High Precision: 0.7559572222222223\n",
    "* All Precision: 0.7057128042328042\n",
    "\n",
    "* Low Recall: 0.21294207683498362\n",
    "* Med Recall: 0.14992896860078572\n",
    "* High Recall: 0.23615352781749904\n",
    "* All Recall: 0.19967485775108945\n",
    "\n",
    "NMF\n",
    "* Low Precision: 0.6312755555555556\n",
    "* Med Precision: 0.598235238095238\n",
    "* High Precision: 0.6549547619047619\n",
    "* All Precision: 0.6281551851851852\n",
    "\n",
    "* Low Recall: 0.1965284343490094\n",
    "* Med Recall: 0.1295440782539194\n",
    "* High Recall: 0.20650777629230252\n",
    "* All Recall: 0.1775267629650771\n",
    "\n",
    "CoClustering\n",
    "* Low Precision: 0.672306507936508\n",
    "* Med Precision: 0.6898487301587302\n",
    "* High Precision: 0.7660446031746032\n",
    "* All Precision: 0.709399947089947\n",
    "\n",
    "* Low Recall: 0.21368047819309094\n",
    "* Med Recall: 0.15228889489132955\n",
    "* High Recall: 0.2421086986639204\n",
    "* All Recall: 0.20269269058278033"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
